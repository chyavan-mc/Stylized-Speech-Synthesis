{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from os.path import getsize\n",
    "from os import remove\n",
    "from IPython.display import Audio\n",
    "from config import CONFIG\n",
    "\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from gtts import gTTS\n",
    "from tensorflow import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Read the voice data and manually pick out ~3 audios for each celebrity where the speech can easily be transcribed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CONFIG.get(\"files\", \"base_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_signature = df.iloc[\n",
    "    [\n",
    "        0,  1,  2,\n",
    "        205,207,208,\n",
    "        388,390,391,\n",
    "        519,524,525,\n",
    "        692,694,698,\n",
    "        844,845,849,\n",
    "        1048,1044,1051,\n",
    "        1242,1243,1248,\n",
    "        1367,1368,1369,\n",
    "        1567,1575,1576,\n",
    "        1656,1659,1660,\n",
    "        1856,1857,1858,\n",
    "        1972,1974,1976,\n",
    "        2179,2183,2126,\n",
    "        2277,2278,2281,\n",
    "        2477,2478,2479,\n",
    "        2665,2666,2667,\n",
    "        2865,2866,2867,\n",
    "        3065,3071,3067,\n",
    "        3266,3267,3271,\n",
    "        3386,3387,3393,\n",
    "        3558,3563,3565,\n",
    "        3760,3761,3762,\n",
    "        3958,3959,3967,\n",
    "        4164,4165,4167,\n",
    "        4215,4216,4217\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_signature[\"text\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filepath</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10000</td>\n",
       "      <td>..\\data\\vox1_indian\\id10000\\GoogleSamples\\0000...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10000</td>\n",
       "      <td>..\\data\\vox1_indian\\id10000\\GoogleSamples\\0009...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10000</td>\n",
       "      <td>..\\data\\vox1_indian\\id10000\\GoogleSamples\\0019...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>id10001</td>\n",
       "      <td>..\\data\\vox1_indian\\id10001\\ProfAudio\\audio13.wav</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>id10001</td>\n",
       "      <td>..\\data\\vox1_indian\\id10001\\ProfAudio\\audio45.wav</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker_id                                           filepath text\n",
       "0      id10000  ..\\data\\vox1_indian\\id10000\\GoogleSamples\\0000...     \n",
       "1      id10000  ..\\data\\vox1_indian\\id10000\\GoogleSamples\\0009...     \n",
       "2      id10000  ..\\data\\vox1_indian\\id10000\\GoogleSamples\\0019...     \n",
       "205    id10001  ..\\data\\vox1_indian\\id10001\\ProfAudio\\audio13.wav     \n",
       "207    id10001  ..\\data\\vox1_indian\\id10001\\ProfAudio\\audio45.wav     "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_signature.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Find the duration to which all audio files will be cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.960090702947846"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smallest_file = min(df[\"filepath\"], key=getsize)\n",
    "y, sr = librosa.load(smallest_file)\n",
    "y, _ = librosa.effects.trim(y)\n",
    "duration = librosa.get_duration(y=y, sr=sr)\n",
    "display(duration)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Manually transcribe the audio to match google assistant as closely as possible (Even if it means, including a misspelled transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_signature = convert_to_signature.copy()\n",
    "texts = [\n",
    "    \"substantial cartridge offense proliferation fancy maternity\",\n",
    "    \"afraid galoshes wets vegetarian breezy zinc interlace\",\n",
    "    \"nebulous malar trips here curly collateral raises chad\",\n",
    "    \"you know maybe it's in a more severe stage, uh, as and as supposed\",\n",
    "    \"think about... the columns are the features, right?\",\n",
    "    \"each direction of the output! then you need to break it up into multiple\",\n",
    "    \"came back to me and then again went back to hire us, so it should not be like\",\n",
    "    \"e you know people will be overcritical about it I think people kinda understood\",\n",
    "    \"know that whatever I'm doing is being loved by people and I do get\",\n",
    "    \"now what I mean is the the the script we had in front of us all of us spent\",\n",
    "    \"um, I don't do too much to look after myself, but what I do\",\n",
    "    \"yes irrespective of what religion they come from and a few\",\n",
    "    \"understand and get out of it, lot of people like like I'm seeing now the whole industry\",\n",
    "    \"don't care what I'm doing, when you really don't care what I've had to\",\n",
    "    \"buh imin general people! I really believe that people talk rubbish\",\n",
    "    \"uh he's not uh uh a guy who gets happy very fast; some uh\",\n",
    "    \"with a vapas you you become normal and you start playing that character much faster\",\n",
    "    \"uhh gets it from outside and she writes it down, and a\",\n",
    "    \"mujhe kaam mil raha hai or kuch log merei saath kaam karna chaate hai\",\n",
    "    \"countries like united states of america russia meh, china such\",\n",
    "    \"I just consider myself very fortunate to have uh, being able to uh\",\n",
    "    \"gap between the disney one and uh, our warner brothers one, umm I\",\n",
    "    \"I'd just broken up with my boyfriend it was really, traumatic is pressed up\",\n",
    "    \"uh they fall in love because of the similar interest where she reelly\",\n",
    "    \"body starts giving signal, those kind of singals you know uh, where\",\n",
    "    \"that you know aap ko lagta hai key yaar ka e baar bolt eh key aapko moks mil jaaye\",\n",
    "    \"daniel lewis uh, Phillips similar hopper which is not there, mcbrando which\",\n",
    "    \"I know, that I have things to say that will be very important\",\n",
    "    \"kals so I think we need more of this lot I am designing scripts\",\n",
    "    \"and and we've shot every action sequence and then we've shot it here that I believe\",\n",
    "    \"action meh toh mujhe itna lagta nai hai key interest hai lekin direction\",\n",
    "    \"league and people really look up to, and the the the way advertisements\",\n",
    "    \"and publicly, individual who doesn't have an iota of respect\",\n",
    "    \"achieveable it's doable because uh, hollywood also a post slum\",\n",
    "    \"on a, the late indira gandhi, I would like to do\",\n",
    "    \"all wrong which none of that is moralistic she's using her body\",\n",
    "    \"or to serve art in it, we all become actors because we are\",\n",
    "    \"xx\",\n",
    "    \"to people with no resources, and where\",\n",
    "    \"so after about 6 months, in fact I was in\",\n",
    "    \"so english used to bother me and there it was a big\",\n",
    "    \"mujhe mathematics may physics may or in sub subjects may marks bot\",\n",
    "    \"obviously uh, uh, with a title a poster you invite\",\n",
    "    \"uh but whatever heroin to say so, I really want to work with him\",\n",
    "    \"don't ever want to watch a film and look look for myself in it, y'know I don't want to just\",\n",
    "    \"you know he would make you do all kinds of things and and really an\",\n",
    "    \"happily. yeah! and not to get to umm\",\n",
    "    \"a and then of course asking kamal sir y'know what he thought about the character what he wanted\",\n",
    "    \"gin key unhe coy b pressure moment may daaldo\",\n",
    "    \"okay I was comfortable but then I realized with men especially in sports\",\n",
    "    \"a and not being derogatory to them, that's not my friends also\",\n",
    "    \"missions friendships so think ye javani hay divani embodies the entire film\",\n",
    "    \"a he has a little bit popularity on the internet he becomes like an internet sensation\",\n",
    "    \"eh because I'm playing a hero for the first time, you know a larger than life carrot if you see all my\",\n",
    "    \"I mean that's also a great thing and real stardom comes beyond the roads\",\n",
    "    \"so it is not just me as an actor with Erin there's a whole team\",\n",
    "    \"should be, it should be a problem because what?\",\n",
    "    \"it's about how well two people can understand each other and how much they really wanna\",\n",
    "    \"I'm doing my own thing I have my own career I have my own life and nobody\",\n",
    "    \"xx\",\n",
    "    \"instantly in love with it eck romantic thriller it ney time k baad\",\n",
    "    \". I'm known as uh, at home my my mum my\",\n",
    "    \"also, so again I think that that is something that is..\",\n",
    "    \"other product is gonna be, a close to me or I can emulate that\",\n",
    "    \"background where I'm really trained as an actor, or uh uh been on sets\",\n",
    "    \"uhh, so yeah man I think I would like to invite some people next time to come in and try\",\n",
    "    \"because even if my father might not agree with my mom privately but when they act\",\n",
    "    \"black, I used to like beg the assistants to like take me and pick me up and all it's\",\n",
    "    \"thing is umm, I don't know he never reacts to this but I've\",\n",
    "    \"think that's something that's been played with even though, it's not to the\",\n",
    "    \"and you get an idea of how hard they must've what were we trying to do we were trying to\",\n",
    "    \"thing because you know it's not it's not a book that gives you a happy feeling or a book that gives you a sad\",\n",
    "    \"yeah, I was it was too exciting for me to get to do this role and to\",\n",
    "    \"the interesting thing about, the way this character\",\n",
    "    \"very important backstory that he's added to begum's\",\n",
    "    \"when I looked at myself in the mirror I couldn't believe it was me\",\n",
    "    \"this phase has taught me is that you have to just keep going on, so summary\",\n",
    "    \"kush hota hay in ka I think everyone has, that! y'know\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_signature[\"text\"] = texts\n",
    "convert_to_signature[convert_to_signature[\"text\"] == \"xx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Data Correction for transcription\n",
    "convert_to_signature = convert_to_signature.drop(1974)\n",
    "convert_to_signature.loc[3271, \"filepath\"] = convert_to_signature.loc[3266, \"filepath\"].replace(\"00003\", \"00004\")\n",
    "convert_to_signature.loc[3271, \"text\"] = \"I mean that's what I've learnt from life like everything's a phase everything that's true today will not be true tomorrow\"\n",
    "convert_to_signature.loc[len(convert_to_signature)] = convert_to_signature.loc[2183]\n",
    "convert_to_signature.loc[77, \"text\"] = \"and I, got major row-there was one problem which I was\"\n",
    "convert_to_signature[\"speaker_id\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Convolute the audio and Google Assistant's version of the same audio and get the difference as the signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained recognition model\n",
    "loaded_model = keras.models.load_model(CONFIG.get(\"files\", \"recog_model\"))\n",
    "\n",
    "# Get layerwise weights\n",
    "weights = []\n",
    "for layr in loaded_model.layers:\n",
    "    weights.append(layr.get_weights())\n",
    "\n",
    "# Build only the convolutional part of the network and assign the trained weights\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(128,171,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "\n",
    "for i, layr in enumerate(model.layers):\n",
    "    model.layers[i].set_weights(weights[i])\n",
    "    model.layers[i].trainable = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get the embeddings of the speeches WRT Google's speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(ps):\n",
    "    # Convolute the Spectrogram to get a convoluted 4096 dimensional output (input to decoder)\n",
    "    return model.predict(np.array([ps.reshape((128,171,1))]), verbose=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language = 'en'\n",
    "google_filepath = CONFIG.get(\"files\", \"reconst_models\") # Any directory where we can create and delete the \"temporary\" google audio file\n",
    "\n",
    "def get_embedding(row):\n",
    "    # User Spectrogram\n",
    "    y, sr = librosa.load(row[\"filepath\"])\n",
    "    y = y[:int(sr*duration)]\n",
    "    temp = len(y)\n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    \n",
    "    # Google Spectrogram\n",
    "    tts = gTTS(text=row[\"text\"], lang=language, slow=False)\n",
    "    tts.save(google_filepath + \"temp.wav\")\n",
    "    y, sr = librosa.load(google_filepath + \"temp.wav\")\n",
    "    remove(google_filepath + \"temp.wav\")\n",
    "    speed_factor = (len(y)/int(sr*duration))**(0.25)\n",
    "    y_new = librosa.effects.time_stretch(y, speed_factor)\n",
    "    if len(y_new) > int(sr*duration):\n",
    "        y_new = y_new[:int(sr*duration)]\n",
    "    elif len(y) > int(sr*duration):\n",
    "        y_new = y[:int(sr*duration)]\n",
    "    else:\n",
    "        y_new = librosa.util.fix_length(y, size=int(sr*duration))\n",
    "    ps_google = librosa.feature.melspectrogram(y=y_new, sr=sr)\n",
    "\n",
    "    if temp != len(y_new):\n",
    "        display(row)\n",
    "\n",
    "    return conv(ps) - conv(ps_google)\n",
    "    \n",
    "embedding = get_embedding(convert_to_signature.iloc[50])\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = convert_to_signature.apply(lambda x: get_embedding(x), axis=1)\n",
    "embeddings_df = pd.DataFrame(dict(zip(embeddings.index, embeddings.values))).T\n",
    "embeddings_df = pd.concat([embeddings_df, convert_to_signature], axis=1).drop(columns=[\"filepath\", \"text\"])\n",
    "embeddings_df = embeddings_df.groupby(\"speaker_id\")[[*range(4096)]].mean().reset_index()\n",
    "embeddings_df.to_csv(CONFIG.get(\"files\", \"speaker_embedding\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.167808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.196701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.795374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512082</td>\n",
       "      <td>-0.002412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.693631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.576427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391755</td>\n",
       "      <td>-0.077004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.342671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.293667</td>\n",
       "      <td>-0.105879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.275015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.458128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922944</td>\n",
       "      <td>0.021755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.131275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker_id    0    1    2         3    4    5         6         7    8  ...  \\\n",
       "0    id10000  0.0  0.0  0.0  0.077678  0.0  0.0  0.000000 -0.167808  0.0  ...   \n",
       "1    id10001  0.0  0.0  0.0  0.795374  0.0  0.0  0.512082 -0.002412  0.0  ...   \n",
       "2    id10002  0.0  0.0  0.0 -0.576427  0.0  0.0  0.391755 -0.077004  0.0  ...   \n",
       "3    id10003  0.0  0.0  0.0  0.246919  0.0  0.0  0.293667 -0.105879  0.0  ...   \n",
       "4    id10017  0.0  0.0  0.0 -0.458128  0.0  0.0  0.922944  0.021755  0.0  ...   \n",
       "\n",
       "   4086  4087  4088  4089  4090  4091      4092  4093  4094      4095  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0 -0.196701   0.0   0.0  0.000000  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0 -0.693631   0.0   0.0  0.000000  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0 -0.342671   0.0   0.0  0.000000  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0 -0.275015   0.0   0.0  0.000000  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0 -0.131275   0.0   0.0  0.248438  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
